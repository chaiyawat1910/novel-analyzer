import streamlit as st
import pandas as pd
import altair as alt
from pythainlp import word_tokenize
from pythainlp.util import isthai
from collections import Counter
import graphviz

# --- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö ---
st.set_page_config(page_title="Pro Novel Analyst", page_icon="üïµÔ∏è", layout="wide")

st.title("üïµÔ∏è Pro Novel Analyst: ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ô‡∏¥‡∏¢‡∏≤‡∏¢")
st.info("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå ‡∏´‡∏£‡∏∑‡∏≠ ‡∏ß‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ô‡∏¥‡∏¢‡∏≤‡∏¢ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£")

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
col_input1, col_input2 = st.columns([2, 1])

with col_input1:
    text_input = st.text_area("‡∏ß‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ô‡∏¥‡∏¢‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î):", height=300)

with col_input2:
    st.write("üîß **‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü)**")
    # ‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏™‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡πÄ‡∏≠‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ AI ‡πÄ‡∏î‡∏≤
    char_input = st.text_area("‡πÉ‡∏™‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£ (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏à‡∏∏‡∏•‡∏†‡∏≤‡∏Ñ , ) ‡πÄ‡∏ä‡πà‡∏ô: ‡∏û‡∏£‡∏∞‡πÄ‡∏≠‡∏Å,‡∏ô‡∏≤‡∏á‡πÄ‡∏≠‡∏Å,‡∏ï‡∏±‡∏ß‡∏£‡πâ‡∏≤‡∏¢", height=100)
    
    analyze_btn = st.button("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏ô‡∏µ‡πâ!", type="primary")

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ---
def analyze_sentiment(words):
    # ‡∏Ñ‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå (‡∏â‡∏ö‡∏±‡∏ö‡∏¢‡πà‡∏≠)
    pos_words = ["‡∏£‡∏±‡∏Å", "‡∏î‡∏µ", "‡∏™‡∏∏‡∏Ç", "‡∏™‡∏ß‡∏¢", "‡∏¢‡∏¥‡πâ‡∏°", "‡∏´‡∏±‡∏ß‡πÄ‡∏£‡∏≤‡∏∞", "‡∏ä‡∏≠‡∏ö", "‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô", "‡∏´‡∏ß‡∏≤‡∏ô", "‡∏ï‡∏∑‡πà‡∏ô‡πÄ‡∏ï‡πâ‡∏ô", "‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à"]
    neg_words = ["‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î", "‡∏ï‡∏≤‡∏¢", "‡∏Ü‡πà‡∏≤", "‡πÄ‡∏•‡∏ß", "‡∏£‡πâ‡∏≠‡∏á‡πÑ‡∏´‡πâ", "‡πÄ‡∏à‡πá‡∏ö", "‡πÇ‡∏Å‡∏£‡∏ò", "‡πÄ‡∏®‡∏£‡πâ‡∏≤", "‡∏ó‡∏£‡∏°‡∏≤‡∏ô", "‡∏Å‡∏•‡∏±‡∏ß", "‡∏°‡∏∑‡∏î‡∏°‡∏ô"]
    
    score = 0
    if len(words) > 0:
        pos_cnt = sum(1 for w in words if w in pos_words)
        neg_cnt = sum(1 for w in words if w in neg_words)
        score = pos_cnt - neg_cnt
    return score

if analyze_btn and text_input:
    with st.spinner('‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏ô‡∏¥‡∏¢‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...'):
        
        # 1. Preprocessing
        # ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢/‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
        raw_words = word_tokenize(text_input, engine="newmm")
        words = [w for w in raw_words if w.strip() != "" and isthai(w)]
        
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£
        character_list = []
        if char_input:
            character_list = [c.strip() for c in char_input.split(",") if c.strip() != ""]

        # --- ‡∏™‡∏£‡πâ‡∏≤‡∏á Tabs ‡πÅ‡∏¢‡∏Å‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ---
        tab1, tab2, tab3, tab4 = st.tabs(["üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô", "üìà ‡∏Å‡∏£‡∏≤‡∏ü‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå (Arc)", "üï∏Ô∏è ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£", "üìù ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ã‡πâ‡∏≥"])

        # === TAB 1: Basic Stats ===
        with tab1:
            st.header("‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏° (Overview)")
            col1, col2, col3, col4 = st.columns(4)
            
            n_words = len(words)
            read_time = round(n_words / 200) # ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ 200 ‡∏Ñ‡∏≥/‡∏ô‡∏≤‡∏ó‡∏µ
            
            col1.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", f"{n_words:,}")
            col2.metric("‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì", f"{read_time} ‡∏ô‡∏≤‡∏ó‡∏µ")
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥ (Lexical Diversity)
            vocab = set(words)
            diversity = round((len(vocab) / n_words) * 100, 2)
            col3.metric("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏≥", f"{diversity}%")
            col3.caption("‡∏¢‡∏¥‡πà‡∏á‡∏ô‡πâ‡∏≠‡∏¢ = ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ã‡πâ‡∏≥‡πÄ‡∏¢‡∏≠‡∏∞")

            # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å‡∏á‡πà‡∏≤‡∏¢ (Readability - ‡∏î‡∏π‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ñ‡∏≥‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢)
            avg_len = sum(len(w) for w in words) / n_words
            readability = "‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏°‡∏≤‡∏Å"
            if avg_len > 4: readability = "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á"
            if avg_len > 6: readability = "‡∏†‡∏≤‡∏©‡∏≤‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô/‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£"
            
            col4.metric("‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤", readability)

        # === TAB 2: Sentiment Arc ===
        with tab2:
            st.header("‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á (Emotional Arc)")
            st.write("‡∏Å‡∏£‡∏≤‡∏ü‡∏ô‡∏µ‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏õ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏ô‡∏à‡∏ô‡∏à‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á")
            
            # ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ (Chunks) ‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏∞ 100 ‡∏Ñ‡∏≥ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏û‡∏•‡πá‡∏≠‡∏ï‡∏à‡∏∏‡∏î
            chunk_size = 100
            chunks = [words[i:i + chunk_size] for i in range(0, len(words), chunk_size)]
            
            sentiment_scores = [analyze_sentiment(chunk) for chunk in chunks]
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á Dataframe ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏≤‡∏ü
            chart_data = pd.DataFrame({
                'Position': range(len(sentiment_scores)),
                'Mood Score': sentiment_scores
            })
            
            # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≤‡∏ü
            line_chart = alt.Chart(chart_data).mark_line(interpolate='basis').encode(
                x=alt.X('Position', title='‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á (‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤)'),
                y=alt.Y('Mood Score', title='‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå (‡∏ö‡∏ß‡∏Å/‡∏•‡∏ö)'),
                color=alt.value("#FF4B4B")
            ).properties(height=300)
            
            st.altair_chart(line_chart, use_container_width=True)
            
            if sum(sentiment_scores) > 0:
                st.success("‡πÇ‡∏ó‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°: ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ß‡∏Å (Positive)")
            else:
                st.error("‡πÇ‡∏ó‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°: ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡∏ö/‡∏î‡∏£‡∏≤‡∏°‡πà‡∏≤ (Negative)")

        # === TAB 3: Character Network ===
        with tab3:
            st.header("‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå (Character Network)")
            
            if not character_list:
                st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏î‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü")
            else:
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü
                graph = graphviz.Digraph()
                graph.attr(rankdir='LR')
                
                # ‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå: ‡∏ñ‡πâ‡∏≤‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡πÉ‡∏ô‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô = ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ô
                paragraphs = text_input.split('\n')
                relations = Counter()
                
                # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå
                for para in paragraphs:
                    found_chars = [c for c in character_list if c in para]
                    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 1 ‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡πÉ‡∏ô‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏π‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå
                    if len(found_chars) > 1:
                        for i in range(len(found_chars)):
                            for j in range(i+1, len(found_chars)):
                                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ä‡∏∑‡πà‡∏≠ ‡∏Å-‡∏Æ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏™‡∏•‡∏±‡∏ö‡∏Å‡∏±‡∏ô (A-B ‡∏Å‡∏±‡∏ö B-A ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)
                                pair = tuple(sorted([found_chars[i], found_chars[j]]))
                                relations[pair] += 1
                
                # ‡∏ß‡∏≤‡∏î Nodes ‡πÅ‡∏•‡∏∞ Edges
                for char in character_list:
                    # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ß‡∏á‡∏Å‡∏•‡∏°‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á
                    freq = text_input.count(char)
                    if freq > 0:
                        graph.node(char, label=f"{char}\n({freq})", style='filled', fillcolor='lightblue')
                
                for (char1, char2), weight in relations.items():
                    # ‡πÄ‡∏™‡πâ‡∏ô‡∏´‡∏ô‡∏≤‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠‡∏Å‡∏±‡∏ô
                    graph.edge(char1, char2, penwidth=str(weight/2 + 1), label=str(weight))
                
                st.graphviz_chart(graph)
                st.caption("*‡πÄ‡∏™‡πâ‡∏ô‡∏¢‡∏¥‡πà‡∏á‡∏´‡∏ô‡∏≤ ‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡∏™‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏â‡∏≤‡∏Å‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏ö‡πà‡∏≠‡∏¢")

        # === TAB 4: Word Repetition ===
        with tab4:
            st.header("‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ã‡πâ‡∏≥/‡∏Ñ‡∏≥‡∏ü‡∏∏‡πà‡∏°‡πÄ‡∏ü‡∏∑‡∏≠‡∏¢")
            
            # ‡∏ô‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà
            word_counts = Counter(words)
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô DataFrame
            df_words = pd.DataFrame(word_counts.most_common(20), columns=['‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á'])
            
            col_a, col_b = st.columns(2)
            
            with col_a:
                st.write("üîù **20 ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î**")
                st.dataframe(df_words, use_container_width=True)
                
            with col_b:
                st.write("üìä **‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà**")
                bar_chart = alt.Chart(df_words).mark_bar().encode(
                    x='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á',
                    y=alt.Y('‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå', sort='-x'),
                    color=alt.value('orange')
                )
                st.altair_chart(bar_chart, use_container_width=True)

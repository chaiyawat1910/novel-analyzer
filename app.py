import streamlit as st
import pandas as pd
import altair as alt
from pythainlp import word_tokenize
from pythainlp.util import isthai
from pythainlp.tag import NER
from collections import Counter
import graphviz
import io

# --- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö ---
st.set_page_config(page_title="Pro Novel Analyst AI", page_icon="ü§ñ", layout="wide")

st.title("ü§ñ Pro Novel Analyst: ‡∏£‡∏∞‡∏ö‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ô‡∏¥‡∏¢‡∏≤‡∏¢‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞")
st.info("‡∏≠‡∏±‡∏õ‡πÄ‡∏Å‡∏£‡∏î‡πÉ‡∏´‡∏°‡πà! ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå ‡πÅ‡∏•‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£/‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥")

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
col_left, col_right = st.columns([1, 1])

with col_left:
    st.subheader("1. ‡πÉ‡∏™‡πà‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ô‡∏¥‡∏¢‡∏≤‡∏¢")
    input_method = st.radio("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:", ["üìÇ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (.txt)", "‚úçÔ∏è ‡∏ß‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏≠‡∏á"])
    
    novel_text = ""
    
    if input_method == "üìÇ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (.txt)":
        uploaded_file = st.file_uploader("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏¥‡∏¢‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì", type=['txt'])
        if uploaded_file is not None:
            stringio = io.StringIO(uploaded_file.getvalue().decode("utf-8"))
            novel_text = stringio.read()
            st.success(f"‚úÖ ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß {len(novel_text)} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)")
            
    else:
        novel_text = st.text_area("‡∏ß‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ô‡∏¥‡∏¢‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà:", height=300)

with col_right:
    st.subheader("2. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
    manual_chars = st.text_area("‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡πÄ‡∏≠‡∏á (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏à‡∏∏‡∏•‡∏†‡∏≤‡∏Ñ , )", placeholder="‡πÄ‡∏ä‡πà‡∏ô: ‡∏™‡∏°‡∏ä‡∏≤‡∏¢, ‡∏™‡∏°‡∏´‡∏ç‡∏¥‡∏á", height=100)
    analyze_btn = st.button("üöÄ ‡∏™‡∏±‡πà‡∏á AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏ô‡∏µ‡πâ!", type="primary", use_container_width=True)

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô AI (NER Engine) ---
@st.cache_resource
def load_ner_engine():
    return NER("thainer")

def extract_entities(text):
    ner = load_ner_engine()
    tags = ner.tag(text)
    
    entities = {
        "PERSON": [],
        "LOCATION": [],
        "DATE": [],
        "TIME": []
    }
    
    # --- ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÄ‡∏ä‡πá‡∏Ñ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
    for item in tags:
        # ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡πÅ‡∏ö‡∏ö‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Error)
        if len(item) == 3:
            word, pos, tag = item
        elif len(item) == 2:
            word, tag = item
        else:
            continue # ‡∏ñ‡πâ‡∏≤‡∏°‡∏≤‡πÅ‡∏õ‡∏•‡∏Å‡πÜ ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ
            
        # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏° Tag
        if "PERSON" in tag:
            entities["PERSON"].append(word)
        elif "LOCATION" in tag:
            entities["LOCATION"].append(word)
        elif "DATE" in tag:
            entities["DATE"].append(word)
        elif "TIME" in tag:
            entities["TIME"].append(word)
            
    return entities

def analyze_sentiment(words):
    pos_words = ["‡∏£‡∏±‡∏Å", "‡∏î‡∏µ", "‡∏™‡∏∏‡∏Ç", "‡∏™‡∏ß‡∏¢", "‡∏¢‡∏¥‡πâ‡∏°", "‡∏´‡∏±‡∏ß‡πÄ‡∏£‡∏≤‡∏∞", "‡∏ä‡∏≠‡∏ö", "‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô", "‡∏´‡∏ß‡∏≤‡∏ô", "‡∏ï‡∏∑‡πà‡∏ô‡πÄ‡∏ï‡πâ‡∏ô", "‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à", "‡∏£‡∏≠‡∏î", "‡∏ä‡∏ô‡∏∞"]
    neg_words = ["‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î", "‡∏ï‡∏≤‡∏¢", "‡∏Ü‡πà‡∏≤", "‡πÄ‡∏•‡∏ß", "‡∏£‡πâ‡∏≠‡∏á‡πÑ‡∏´‡πâ", "‡πÄ‡∏à‡πá‡∏ö", "‡πÇ‡∏Å‡∏£‡∏ò
